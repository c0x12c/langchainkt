package langchainkt.classification

import kotlin.math.max
import langchainkt.data.embedding.Embedding
import langchainkt.internal.Validators
import langchainkt.model.embedding.EmbeddingModel
import langchainkt.store.embedding.CosineSimilarity
import langchainkt.store.embedding.RelevanceScore

/**
 * A [TextClassifier] that uses an [EmbeddingModel] and predefined examples to perform classification.
 * Classification is done by comparing the embedding of the text being classified with the embeddings of predefined examples.
 * The classification quality improves with a greater number of examples for each label.
 * Examples can be easily generated by the LLM.
 *
 *
 * Example:
 * <pre>`enum Sentiment {
 * POSITIVE, NEUTRAL, NEGATIVE
 * }
 *
 * Map<Sentiment, List<String>> examples = Map.of(
 * POSITIVE, List.of("This is great!", "Wow, awesome!"),
 * NEUTRAL,  List.of("Well, it's fine", "It's ok"),
 * NEGATIVE, List.of("It is pretty bad", "Worst experience ever!")
 * );
 *
 * EmbeddingModel embeddingModel = new AllMiniLmL6V2QuantizedEmbeddingModel();
 *
 * TextClassifier<Sentiment> classifier = new EmbeddingModelTextClassifier<>(embeddingModel, examples);
 *
 * List<Sentiment> sentiments = classifier.classify("Awesome!");
 * System.out.println(sentiments); // [POSITIVE]
`</pre> *
 *
 * Creates a classifier.
 *
 * @param embeddingModel      The embedding model used for embedding both the examples and the text to be classified.
 * @param examplesByLabel     A map containing examples of texts for each label.
 * The more examples, the better. Examples can be easily generated by the LLM.
 * @param maxResults          The maximum number of labels to return for each classification.
 * @param minScore            The minimum similarity score required for classification, in the range [0..1].
 * Labels scoring lower than this value will be discarded.
 * @param meanToMaxScoreRatio A ratio, in the range [0..1], between the mean and max scores used for calculating
 * the final score.
 * During classification, the embeddings of examples for each label are compared to
 * the embedding of the text being classified.
 * This results in two metrics: the mean and max scores.
 * The mean score is the average similarity score for all examples associated with a given label.
 * The max score is the highest similarity score, corresponding to the example most
 * similar to the text being classified.
 * A value of 0 means that only the mean score will be used for ranking labels.
 * A value of 0.5 means that both scores will contribute equally to the final score.
 * A value of 1 means that only the max score will be used for ranking labels.
 * Creates a classifier with the default values for [.maxResults] (1), [.minScore] (0)
 * and [.meanToMaxScoreRatio] (0.5).
 * @param <E> Enum that is the result of classification.
 * The more examples, the better. Examples can be easily generated by the LLM.
</E> */
class EmbeddingModelTextClassifier<E : Enum<E>> @JvmOverloads constructor(
  private val embeddingModel: EmbeddingModel,
  examplesByLabel: Map<E, MutableCollection<String>>,
  maxResults: Int = 1,
  minScore: Double = 0.0,
  meanToMaxScoreRatio: Double = 0.5
) : TextClassifier<E> {
  private val exampleEmbeddingsByLabel: MutableMap<E, List<Embedding>>
  private val maxResults: Int
  private val minScore: Double
  private val meanToMaxScoreRatio: Double

  init {
    exampleEmbeddingsByLabel = HashMap()
    examplesByLabel.forEach { (label: E, examples: MutableCollection<String>) ->
      exampleEmbeddingsByLabel[label] = examples.map { embeddingModel.embed(it).content() }
    }
    this.maxResults = Validators.ensureGreaterThanZero(maxResults, "maxResults")
    this.minScore = Validators.ensureBetween(minScore, 0.0, 1.0, "minScore")
    this.meanToMaxScoreRatio = Validators.ensureBetween(meanToMaxScoreRatio, 0.0, 1.0, "meanToMaxScoreRatio")
  }

  override fun classify(text: String): List<E> {
    val textEmbedding = embeddingModel.embed(text).content()
    val labelsWithScores: MutableList<LabelWithScore> = ArrayList()
    exampleEmbeddingsByLabel.forEach { (label: E, exampleEmbeddings: List<Embedding>) ->
      var meanScore = 0.0
      var maxScore = 0.0
      for (exampleEmbedding in exampleEmbeddings) {
        val cosineSimilarity = CosineSimilarity.between(textEmbedding, exampleEmbedding)
        val score = RelevanceScore.fromCosineSimilarity(cosineSimilarity)
        meanScore += score
        maxScore = max(score, maxScore)
      }
      meanScore /= exampleEmbeddings.size.toDouble()
      labelsWithScores.add(LabelWithScore(label, aggregatedScore(meanScore, maxScore)))
    }
    return labelsWithScores
      .filter { it: LabelWithScore -> it.score >= minScore } // sorting in descending order to return highest score first
      .sortedBy { labelWithScore: LabelWithScore -> 1 - labelWithScore.score }
      .take(maxResults)
      .map { it: LabelWithScore -> it.label }
  }

  private fun aggregatedScore(meanScore: Double, maxScore: Double): Double {
    return meanToMaxScoreRatio * meanScore + (1 - meanToMaxScoreRatio) * maxScore
  }

  private inner class LabelWithScore(
    val label: E,
    val score: Double
  )
}
