package langchainkt.model

import langchainkt.model.output.Response

interface StreamingResponseHandler<T> {
  /**
   * Invoked each time the language model generates a new token in a textual response.
   * If the model executes a tool instead, this method will not be invoked; [.onComplete] will be invoked instead.
   *
   * @param token The newly generated token, which is a part of the complete response.
   */
  fun onNext(token: String)

  /**
   * Invoked when the language model has finished streaming a response.
   * If the model executes a tool, it is accessible via [AiMessage.toolExecutionRequest].
   *
   * @param response The complete response generated by the language model.
   * For textual responses, it contains all tokens from [.onNext] concatenated.
   */
  fun onComplete(response: Response<T>) {}

  /**
   * This method is invoked when an error occurs during streaming.
   *
   * @param error The error that occurred
   */
  fun onError(error: Throwable?)
}
